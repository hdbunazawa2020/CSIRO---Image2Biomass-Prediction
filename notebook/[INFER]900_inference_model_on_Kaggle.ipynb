{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31695236",
   "metadata": {
    "_cell_guid": "3d91577c-9261-4436-82be-79fce873dabf",
    "_uuid": "4db639e2-6cd5-4a85-a82b-8f2aed7fa83a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-29T04:24:31.885318Z",
     "iopub.status.busy": "2025-12-29T04:24:31.884867Z",
     "iopub.status.idle": "2025-12-29T04:25:32.528521Z",
     "shell.execute_reply": "2025-12-29T04:25:32.527066Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 60.650498,
     "end_time": "2025-12-29T04:25:32.530972",
     "exception": false,
     "start_time": "2025-12-29T04:24:31.880474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå± Seed fixed: 1129\n",
      "================================================================================\n",
      "üìù Make submission\n",
      "================================================================================\n",
      "[INFO] comp_dir auto-detected: /kaggle/input/csiro-biomass\n",
      "[INFO] device=cuda use_amp=True\n",
      "[INFO] comp_dir=/kaggle/input/csiro-biomass\n",
      "[INFO] artifact_root=/kaggle/input/csiro-artifacts\n",
      "[INFO] csv=test.csv  sample_sub=sample_submission.csv\n",
      "[INFO] ckpts=['best_fold0.pth']\n",
      "================================================================================\n",
      "üéØ Ensemble inference\n",
      "================================================================================\n",
      "[INFO] device=cuda  amp=True\n",
      "[INFO] img_size=224  targets=['Dry_Green_g', 'Dry_Clover_g', 'Dry_Dead_g', 'GDM_g', 'Dry_Total_g']  log1p=True\n",
      "[INFO] #ckpts=1\n",
      "[WARN] load_state_dict: missing=342 unexpected=342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41fc2b7c2814c2faa4ea53147381e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "üîÆ infer:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved: submission.csv  rows=5\n",
      "================================================================================\n",
      "üìã Sanity check\n",
      "================================================================================\n",
      "rows: 5\n",
      "cols: ['sample_id', 'target']\n",
      "nan: 0\n",
      "min/max: 0.0 16.72542381286621\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   0.000000\n",
      "1    ID1001187975__Dry_Dead_g   0.250154\n",
      "2   ID1001187975__Dry_Green_g  16.725424\n",
      "3   ID1001187975__Dry_Total_g   0.000000\n",
      "4         ID1001187975__GDM_g   0.391756\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CSIRO Image2Biomass - Robust Inference Notebook (Kaggle)\n",
    "# - CPU-only / hidden rerun friendly\n",
    "# - Generates submission.csv\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # truncated image„ÅßËêΩ„Å°„Å´„Åè„Åè\n",
    "\n",
    "# display„ÅåÁÑ°„ÅÑÁí∞Â¢É„Åß„ÇÇËêΩ„Å°„Å™„ÅÑ„Çà„ÅÜ„Å´„Åô„Çã\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    display = None\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Utils\n",
    "# --------------------------\n",
    "def sep(title: str, n: int = 80):\n",
    "    print(\"=\" * n)\n",
    "    print(title)\n",
    "    print(\"=\" * n)\n",
    "\n",
    "\n",
    "def show_df(df: pd.DataFrame, n: int = 3, tail: bool = False):\n",
    "    \"\"\"display„ÅåÁÑ°„ÅÑÁí∞Â¢É„Åß„ÇÇËêΩ„Å°„Å™„ÅÑ DataFrame Ë°®Á§∫.\"\"\"\n",
    "    print(\"shape:\", df.shape)\n",
    "    if display is not None:\n",
    "        display(df.head(n))\n",
    "        if tail:\n",
    "            display(df.tail(n))\n",
    "    else:\n",
    "        print(df.head(n).to_string(index=False))\n",
    "        if tail:\n",
    "            print(df.tail(n).to_string(index=False))\n",
    "\n",
    "\n",
    "def seed_everything(seed: int = 1129) -> None:\n",
    "    \"\"\"CPU-only„Åß„ÇÇÂÆâÂÖ®„Å™seedÂõ∫ÂÆö„ÄÇ\"\"\"\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    print(f\"üå± Seed fixed: {seed}\")\n",
    "\n",
    "\n",
    "def _load_yaml(path: Path) -> Dict:\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "def glob_walk(root: Path, pattern: str) -> List[Path]:\n",
    "    return sorted(list(Path(root).glob(pattern)))\n",
    "\n",
    "\n",
    "def find_comp_dir(comp_root: Optional[str] = None) -> Path:\n",
    "    \"\"\"\n",
    "    comp dataset root „ÇíËá™ÂãïÊ§úÂá∫„ÄÇ\n",
    "    /kaggle/input ÈÖç‰∏ã„Åã„Çâ test.csv „Å® sample_submission.csv „ÇíÂê´„ÇÄdir„ÇíÊé¢„Åô„ÄÇ\n",
    "    \"\"\"\n",
    "    if comp_root is not None:\n",
    "        p = Path(comp_root)\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(f\"comp_root not found: {p}\")\n",
    "        return p\n",
    "\n",
    "    base = Path(\"/kaggle/input\")\n",
    "    if not base.exists():\n",
    "        raise FileNotFoundError(\"'/kaggle/input' not found. Are you running on Kaggle?\")\n",
    "\n",
    "    candidates = []\n",
    "    for d in base.iterdir():\n",
    "        if d.is_dir() and (d / \"sample_submission.csv\").exists():\n",
    "            # test.csv „ÅåÁÑ°„ÅÑ„Ç≥„É≥„Éö„ÇÇ„ÅÇ„Çã„Åå„ÄÅÂü∫Êú¨„ÅØ„ÅÇ„ÇãÂâçÊèê\n",
    "            if (d / \"test.csv\").exists() or (d / \"train.csv\").exists():\n",
    "                candidates.append(d)\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        raise FileNotFoundError(\"Could not find competition dataset dir with sample_submission.csv\")\n",
    "\n",
    "    # csiro„Å£„ÅΩ„ÅÑÂêçÂâç„ÇíÂÑ™ÂÖà\n",
    "    candidates_sorted = sorted(\n",
    "        candidates,\n",
    "        key=lambda x: ((\"csiro\" not in x.name.lower()), x.name.lower())\n",
    "    )\n",
    "    chosen = candidates_sorted[0]\n",
    "    print(f\"[INFO] comp_dir auto-detected: {chosen}\")\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def find_artifact_root(artifact_root: Optional[str] = None) -> Path:\n",
    "    \"\"\"\n",
    "    artifact_root „ÇíËá™ÂãïÊ§úÂá∫„ÄÇ\n",
    "    /kaggle/input ÈÖç‰∏ã„Åã„Çâ yaml/config.yaml „Å® model/*.pth „ÇíÂê´„ÇÄdir„ÇíÊé¢„Åô„ÄÇ\n",
    "    \"\"\"\n",
    "    if artifact_root is not None:\n",
    "        p = Path(artifact_root)\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(f\"artifact_root not found: {p}\")\n",
    "        return p\n",
    "\n",
    "    base = Path(\"/kaggle/input\")\n",
    "    candidates = []\n",
    "    for d in base.iterdir():\n",
    "        if not d.is_dir():\n",
    "            continue\n",
    "        cfg = d / \"yaml\" / \"config.yaml\"\n",
    "        mdl = d / \"model\"\n",
    "        if cfg.exists() and mdl.exists() and len(list(mdl.glob(\"*.pth\"))) > 0:\n",
    "            candidates.append(d)\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        raise FileNotFoundError(\"Could not auto-detect artifact_root (need yaml/config.yaml and model/*.pth).\")\n",
    "\n",
    "    chosen = sorted(candidates, key=lambda x: x.name.lower())[0]\n",
    "    print(f\"[INFO] artifact_root auto-detected: {chosen}\")\n",
    "    return chosen\n",
    "\n",
    "\n",
    "def _pick_state_dict(ckpt: Dict) -> Dict:\n",
    "    \"\"\"checkpoint dict„Åã„Çâ state_dict „ÇíÊäΩÂá∫„Åó„ÄÅÂøÖË¶Å„Å™„Çâ 'module.' „ÇíÂâ•„Åå„Åô„ÄÇ\"\"\"\n",
    "    for key in [\"model_state_dict\", \"state_dict\", \"model\"]:\n",
    "        if key in ckpt and isinstance(ckpt[key], dict):\n",
    "            sd = ckpt[key]\n",
    "            break\n",
    "    else:\n",
    "        # Áõ¥„Å´ state_dict „Å£„ÅΩ„ÅÑÂ†¥Âêà\n",
    "        if isinstance(ckpt, dict) and all(isinstance(k, str) for k in ckpt.keys()):\n",
    "            sd = ckpt\n",
    "        else:\n",
    "            raise KeyError(\"state_dict not found in checkpoint\")\n",
    "\n",
    "    # DDPÁ≠â„Åß module. „Åå‰ªò„ÅÑ„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØÂâ•„Åå„Åô\n",
    "    keys = list(sd.keys())\n",
    "    if len(keys) > 0 and all(k.startswith(\"module.\") for k in keys):\n",
    "        sd = {k[len(\"module.\"):]: v for k, v in sd.items()}\n",
    "    return sd\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Model\n",
    "# --------------------------\n",
    "class ConvNeXtRegressor(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: str = \"convnext_base\",\n",
    "        pretrained: bool = False,\n",
    "        num_targets: int = 5,\n",
    "        in_chans: int = 3,\n",
    "        drop_rate: float = 0.0,\n",
    "        drop_path_rate: float = 0.0,\n",
    "        head_dropout: float = 0.0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone,\n",
    "            pretrained=pretrained,   # Kaggle hidden„Åß„ÅØFalseÊé®Â•®\n",
    "            num_classes=0,\n",
    "            global_pool=\"avg\",\n",
    "            in_chans=in_chans,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "        )\n",
    "        feat_dim = self.backbone.num_features\n",
    "\n",
    "        self.head_dropout = nn.Dropout(head_dropout) if head_dropout and head_dropout > 0 else nn.Identity()\n",
    "        self.head = nn.Linear(feat_dim, num_targets)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        feat = self.backbone(x)\n",
    "        feat = self.head_dropout(feat)\n",
    "        return self.head(feat)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Transform / Dataset\n",
    "# --------------------------\n",
    "def build_infer_transform(img_size: int, mean: List[float], std: List[float]) -> A.Compose:\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df_unique: pd.DataFrame,\n",
    "        data_root: Path,\n",
    "        transform: A.Compose,\n",
    "        fallback_size: int = 256,\n",
    "    ):\n",
    "        self.df = df_unique.reset_index(drop=True)\n",
    "        self.data_root = Path(data_root)\n",
    "        self.transform = transform\n",
    "        self.fallback_size = int(fallback_size)\n",
    "\n",
    "        self.image_paths = self.df[\"image_path\"].astype(str).values\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        rel_path = self.image_paths[idx]\n",
    "        img_path = self.data_root / rel_path\n",
    "\n",
    "        try:\n",
    "            with Image.open(img_path) as im:\n",
    "                im = im.convert(\"RGB\")\n",
    "                img = np.array(im)\n",
    "        except Exception:\n",
    "            # hidden„ÅßÂ£ä„Çå/Ê¨†Êêç„ÅåÊ∑∑„Åò„Å£„Å¶„ÇÇËêΩ„Å°„Å™„ÅÑÔºà„Å®„Å´„Åã„ÅèÂÆåËµ∞ÂÑ™ÂÖàÔºâ\n",
    "            img = np.zeros((self.fallback_size, self.fallback_size, 3), dtype=np.uint8)\n",
    "\n",
    "        x = self.transform(image=img)[\"image\"]\n",
    "        return {\"image\": x, \"image_path\": rel_path}\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Inference core\n",
    "# --------------------------\n",
    "@torch.inference_mode()\n",
    "def predict_one_ckpt(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    use_amp: bool = True,\n",
    ") -> Tuple[List[str], np.ndarray]:\n",
    "    model.eval()\n",
    "\n",
    "    paths_all: List[str] = []\n",
    "    preds_all: List[np.ndarray] = []\n",
    "\n",
    "    amp_enabled = bool(use_amp and device.type == \"cuda\")\n",
    "    amp_device_type = device.type  # 'cuda' or 'cpu'\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"üîÆ infer\", leave=False):\n",
    "        x = batch[\"image\"].to(device, non_blocking=(device.type == \"cuda\"))\n",
    "\n",
    "        with autocast(device_type=amp_device_type, enabled=amp_enabled):\n",
    "            pred = model(x)\n",
    "\n",
    "        preds_all.append(pred.float().cpu().numpy())\n",
    "        paths_all.extend(list(batch[\"image_path\"]))\n",
    "\n",
    "    preds = np.concatenate(preds_all, axis=0)\n",
    "    return paths_all, preds\n",
    "\n",
    "\n",
    "def ensemble_predict(\n",
    "    cfg: Dict,\n",
    "    ckpt_paths: List[Path],\n",
    "    unique_test_df: pd.DataFrame,\n",
    "    data_root: Path,\n",
    "    device: torch.device,\n",
    "    batch_size: int = 64,\n",
    "    num_workers: int = 2,\n",
    "    use_amp: bool = True,\n",
    "    enforce_consistency: bool = True,  # GDM/Dry_Total„ÇíÂÜçË®àÁÆó„Åó„Å¶Êï¥ÂêàÊÄß„ÇíÂèñ„Çã\n",
    ") -> pd.DataFrame:\n",
    "    sep(\"üéØ Ensemble inference\")\n",
    "\n",
    "    # config\n",
    "    img_size = int(cfg.get(\"img_size\", 224))\n",
    "    norm = cfg.get(\"normalize\", {})\n",
    "    mean = norm.get(\"mean\", [0.485, 0.456, 0.406])\n",
    "    std = norm.get(\"std\", [0.229, 0.224, 0.225])\n",
    "\n",
    "    # ‚úÖ target_cols „ÅØ config „ÇíÊ≠£„Å®„Åô„ÇãÔºàÈ†ÜÂ∫è„Ç∫„É¨Èò≤Ê≠¢Ôºâ\n",
    "    target_cols = list(cfg.get(\"target_cols\", []))\n",
    "    if len(target_cols) == 0:\n",
    "        # ÊúÄÁµÇfallback\n",
    "        target_cols = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "\n",
    "    use_log1p_target = bool(cfg.get(\"use_log1p_target\", True))\n",
    "\n",
    "    print(f\"[INFO] device={device}  amp={bool(use_amp and device.type=='cuda')}\")\n",
    "    print(f\"[INFO] img_size={img_size}  targets={target_cols}  log1p={use_log1p_target}\")\n",
    "    print(f\"[INFO] #ckpts={len(ckpt_paths)}\")\n",
    "\n",
    "    tfm = build_infer_transform(img_size, mean, std)\n",
    "    ds = TestImageDataset(unique_test_df, data_root=data_root, transform=tfm)\n",
    "\n",
    "    # hidden rerun„ÅØCPU„ÅÆÂèØËÉΩÊÄß„ÅåÈ´ò„ÅÑ ‚Üí num_workers=0„ÅåÂÆâÂÆö\n",
    "    nw = int(num_workers) if device.type == \"cuda\" else 0\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=int(batch_size),\n",
    "        shuffle=False,\n",
    "        num_workers=nw,\n",
    "        pin_memory=(device.type == \"cuda\"),\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    pred_sum = None\n",
    "    paths_ref = None\n",
    "\n",
    "    for ckpt_path in ckpt_paths:\n",
    "        # build model\n",
    "        model_cfg = cfg.get(\"model\", {})\n",
    "        model = ConvNeXtRegressor(\n",
    "            backbone=str(model_cfg.get(\"backbone\", \"convnext_base\")),\n",
    "            pretrained=False,\n",
    "            num_targets=len(target_cols),\n",
    "            in_chans=int(model_cfg.get(\"in_chans\", 3)),\n",
    "            drop_rate=float(model_cfg.get(\"drop_rate\", 0.0)),\n",
    "            drop_path_rate=float(model_cfg.get(\"drop_path_rate\", 0.0)),\n",
    "            head_dropout=float(model_cfg.get(\"head_dropout\", 0.0)),\n",
    "        ).to(device)\n",
    "\n",
    "        # load checkpoint\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "        state_dict = _pick_state_dict(ckpt)\n",
    "        missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "        if len(missing) > 0 or len(unexpected) > 0:\n",
    "            print(f\"[WARN] load_state_dict: missing={len(missing)} unexpected={len(unexpected)}\")\n",
    "\n",
    "        # predict\n",
    "        paths, pred = predict_one_ckpt(model, loader, device=device, use_amp=use_amp)\n",
    "\n",
    "        if paths_ref is None:\n",
    "            paths_ref = paths\n",
    "        else:\n",
    "            # È†ÜÂ∫è„ÅÆ‰∏ÄËá¥„ÅåÂ¥©„Çå„Çã„Å®Ëá¥ÂëΩÁöÑ\n",
    "            if paths_ref != paths:\n",
    "                raise RuntimeError(\"Image order mismatch across checkpoints\")\n",
    "\n",
    "        pred_sum = pred if pred_sum is None else (pred_sum + pred)\n",
    "\n",
    "        # cleanup\n",
    "        del model\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    preds = pred_sum / float(len(ckpt_paths))\n",
    "\n",
    "    # log1p -> raw\n",
    "    if use_log1p_target:\n",
    "        preds = np.expm1(np.clip(preds, -20.0, 20.0))\n",
    "\n",
    "    # mass is non-negative\n",
    "    preds = np.clip(preds, 0.0, None)\n",
    "\n",
    "    pred_df = pd.DataFrame({\"image_path\": paths_ref})\n",
    "    for j, col in enumerate(target_cols):\n",
    "        pred_df[col] = preds[:, j].astype(np.float32)\n",
    "\n",
    "    # optional: enforce consistency (GDM = Green + Clover, Total = GDM + Dead)\n",
    "    if enforce_consistency:\n",
    "        if {\"Dry_Green_g\", \"Dry_Clover_g\", \"GDM_g\"}.issubset(pred_df.columns):\n",
    "            pred_df[\"GDM_g\"] = pred_df[\"Dry_Green_g\"] + pred_df[\"Dry_Clover_g\"]\n",
    "        if {\"GDM_g\", \"Dry_Dead_g\", \"Dry_Total_g\"}.issubset(pred_df.columns):\n",
    "            pred_df[\"Dry_Total_g\"] = pred_df[\"GDM_g\"] + pred_df[\"Dry_Dead_g\"]\n",
    "\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Submission\n",
    "# --------------------------\n",
    "def pick_ckpt_paths(artifact_root: Path, fold: str = \"0\") -> List[Path]:\n",
    "    model_dir = artifact_root / \"model\"\n",
    "    if not model_dir.exists():\n",
    "        raise FileNotFoundError(f\"model dir not found: {model_dir}\")\n",
    "\n",
    "    fold_u = str(fold).upper()\n",
    "    if fold_u == \"ALL\":\n",
    "        paths = sorted(model_dir.glob(\"best_fold*.pth\"))\n",
    "        if len(paths) == 0:\n",
    "            paths = sorted(model_dir.glob(\"*.pth\"))\n",
    "        return paths\n",
    "\n",
    "    # single fold\n",
    "    p1 = model_dir / f\"best_fold{fold}.pth\"\n",
    "    if p1.exists():\n",
    "        return [p1]\n",
    "\n",
    "    # fallback pattern\n",
    "    paths = sorted(model_dir.glob(f\"*fold{fold}*.pth\"))\n",
    "    if len(paths) > 0:\n",
    "        return paths\n",
    "\n",
    "    # final fallback\n",
    "    paths = sorted(model_dir.glob(\"*.pth\"))\n",
    "    if len(paths) == 1:\n",
    "        return paths\n",
    "\n",
    "    raise FileNotFoundError(f\"No checkpoint found for fold={fold} under {model_dir}\")\n",
    "\n",
    "\n",
    "def make_submission(\n",
    "    artifact_root: Optional[str] = \"/kaggle/input/csiro-artifacts\",\n",
    "    comp_root: Optional[str] = None,\n",
    "    output_csv: str = \"submission.csv\",\n",
    "    fold: str = \"0\",\n",
    "    batch_size: int = 64,\n",
    "    num_workers: int = 2,\n",
    "    use_amp: bool = True,\n",
    "    is_test: bool = True,\n",
    "    device: Optional[str] = None,\n",
    "    enforce_consistency: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    sep(\"üìù Make submission\")\n",
    "\n",
    "    # device\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # CPU-onlyÊôÇ„ÅØAMP„ÇíÁÑ°ÂäπÂåñÔºàÂÆâÂÖ®Ôºâ\n",
    "    use_amp = bool(use_amp and device.type == \"cuda\")\n",
    "\n",
    "    # detect dirs\n",
    "    comp_dir = find_comp_dir(comp_root)\n",
    "    artifact_root_path = find_artifact_root(artifact_root)\n",
    "\n",
    "    # choose files\n",
    "    csv_name = \"test.csv\" if is_test else \"train.csv\"\n",
    "    data_csv = comp_dir / csv_name\n",
    "    sub_csv = comp_dir / \"sample_submission.csv\"\n",
    "    if not data_csv.exists():\n",
    "        raise FileNotFoundError(f\"{csv_name} not found: {data_csv}\")\n",
    "    if not sub_csv.exists():\n",
    "        raise FileNotFoundError(f\"sample_submission.csv not found: {sub_csv}\")\n",
    "\n",
    "    # artifacts\n",
    "    cfg_path = artifact_root_path / \"yaml\" / \"config.yaml\"\n",
    "    if not cfg_path.exists():\n",
    "        raise FileNotFoundError(f\"config.yaml not found: {cfg_path}\")\n",
    "    cfg = _load_yaml(cfg_path)\n",
    "\n",
    "    ckpt_paths = pick_ckpt_paths(artifact_root_path, fold=fold)\n",
    "    if len(ckpt_paths) == 0:\n",
    "        raise FileNotFoundError(\"No checkpoints found\")\n",
    "\n",
    "    print(f\"[INFO] device={device} use_amp={use_amp}\")\n",
    "    print(f\"[INFO] comp_dir={comp_dir}\")\n",
    "    print(f\"[INFO] artifact_root={artifact_root_path}\")\n",
    "    print(f\"[INFO] csv={data_csv.name}  sample_sub={sub_csv.name}\")\n",
    "    print(f\"[INFO] ckpts={[p.name for p in ckpt_paths]}\")\n",
    "\n",
    "    # load data\n",
    "    test_df = pd.read_csv(data_csv)\n",
    "    sample_sub_df = pd.read_csv(sub_csv)\n",
    "\n",
    "    # minimal validation\n",
    "    required_cols = {\"sample_id\", \"image_path\", \"target_name\"}\n",
    "    missing_cols = required_cols - set(test_df.columns)\n",
    "    if len(missing_cols) > 0:\n",
    "        raise KeyError(f\"{csv_name} missing columns: {missing_cols}. got={test_df.columns.tolist()}\")\n",
    "\n",
    "    # unique images\n",
    "    unique_test_df = test_df[[\"image_path\"]].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # inference\n",
    "    pred_df = ensemble_predict(\n",
    "        cfg=cfg,\n",
    "        ckpt_paths=ckpt_paths,\n",
    "        unique_test_df=unique_test_df,\n",
    "        data_root=comp_dir,\n",
    "        device=device,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        use_amp=use_amp,\n",
    "        enforce_consistency=enforce_consistency,\n",
    "    )\n",
    "\n",
    "    # long merge: (image_path, target_name) -> target\n",
    "    target_cols = list(cfg.get(\"target_cols\", []))\n",
    "    if len(target_cols) == 0:\n",
    "        target_cols = [\"Dry_Green_g\", \"Dry_Clover_g\", \"Dry_Dead_g\", \"GDM_g\", \"Dry_Total_g\"]\n",
    "\n",
    "    pred_long = pred_df.melt(\n",
    "        id_vars=[\"image_path\"],\n",
    "        value_vars=[c for c in target_cols if c in pred_df.columns],\n",
    "        var_name=\"target_name\",\n",
    "        value_name=\"target\",\n",
    "    )\n",
    "\n",
    "    merged = test_df.merge(pred_long, on=[\"image_path\", \"target_name\"], how=\"left\")\n",
    "\n",
    "    # submission df\n",
    "    submission_df = merged[[\"sample_id\", \"target\"]].copy()\n",
    "\n",
    "    # ‚úÖ sample_submission „ÅÆÈ†Ü„Å´Êï¥ÂàóÔºàÈ†ÜÂ∫èÂâçÊèê„ÅÆÊé°ÁÇπ„ÇÇÊΩ∞„ÅôÔºâ\n",
    "    submission_df = sample_sub_df[[\"sample_id\"]].merge(\n",
    "        submission_df, on=\"sample_id\", how=\"left\", sort=False\n",
    "    )\n",
    "\n",
    "    # ‚úÖ Ê¨†Êêç„ÇÑÈùûÊï∞„Åå„ÅÇ„Å£„Å¶„ÇÇÂÆåËµ∞ÔºàhiddenÂ∑ÆÁï∞ÂØæÁ≠ñÔºâ\n",
    "    submission_df[\"target\"] = pd.to_numeric(submission_df[\"target\"], errors=\"coerce\")\n",
    "    n_nan = int(submission_df[\"target\"].isna().sum())\n",
    "    if n_nan > 0:\n",
    "        print(f\"[WARN] NaN targets after merge: {n_nan} -> fill 0.0\")\n",
    "    submission_df[\"target\"] = submission_df[\"target\"].fillna(0.0)\n",
    "    submission_df[\"target\"] = np.where(\n",
    "        np.isfinite(submission_df[\"target\"].values),\n",
    "        submission_df[\"target\"].values,\n",
    "        0.0\n",
    "    )\n",
    "\n",
    "    # save\n",
    "    submission_df.to_csv(output_csv, index=False)\n",
    "    print(f\"[OK] saved: {output_csv}  rows={len(submission_df)}\")\n",
    "    return submission_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Run\n",
    "# ============================================================\n",
    "seed_everything(1129)\n",
    "\n",
    "# „Åì„Åì„Å†„ÅëÂøÖË¶Å„Å´Âøú„Åò„Å¶Â§â„Åà„Å¶„Åè„Å†„Åï„ÅÑ\n",
    "submission = make_submission(\n",
    "    artifact_root=\"/kaggle/input/csiro-artifacts\",  # Ëá™ÂãïÊ§úÂá∫„Åó„Åü„Åë„Çå„Å∞ None „Å´„Åó„Å¶OK\n",
    "    comp_root=None,                                # Ëá™ÂãïÊ§úÂá∫\n",
    "    output_csv=\"submission.csv\",\n",
    "    fold=\"0\",                                      # \"ALL\" „ÅßÂÖ®fold„Ç¢„É≥„Çµ„É≥„Éñ„É´\n",
    "    batch_size=64,\n",
    "    num_workers=2,                                 # CPUÊôÇ„ÅØËá™Âãï„Åß0„Å´„Å™„Çä„Åæ„Åô\n",
    "    use_amp=True,                                  # CPUÊôÇ„ÅØËá™Âãï„ÅßFalse„Å´„Å™„Çä„Åæ„Åô\n",
    "    is_test=True,\n",
    "    enforce_consistency=False,\n",
    ")\n",
    "\n",
    "# ÊúÄÁµÇ„ÉÅ„Çß„ÉÉ„ÇØÔºàËªΩ„ÇÅÔºâ\n",
    "sep(\"üìã Sanity check\")\n",
    "print(\"rows:\", len(submission))\n",
    "print(\"cols:\", submission.columns.tolist())\n",
    "print(\"nan:\", int(submission.isna().sum().sum()))\n",
    "print(\"min/max:\", float(submission[\"target\"].min()), float(submission[\"target\"].max()))\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8ffe1",
   "metadata": {
    "papermill": {
     "duration": 0.003054,
     "end_time": "2025-12-29T04:25:32.537907",
     "exception": false,
     "start_time": "2025-12-29T04:25:32.534853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "datasetId": 9141994,
     "sourceId": 14320766,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 66.241728,
   "end_time": "2025-12-29T04:25:35.260551",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-29T04:24:29.018823",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0926bbb53cad447fbc55d67c14b656c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d84095ba1d4b45748a25d64cc4625eee",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_37f593501df943b08c3c0f5646a693df",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "28b1039d37f84dba8cab09665fc67d62": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": null
      }
     },
     "2a1fdbb7a4d342689708f81a499164c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "37f593501df943b08c3c0f5646a693df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6668abc65a0a4f3f9349cb3a223a7a89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6a86656190f4410f8806e73f4ed33c41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f6dc804f8394a5bbfbaf695f8f1efe0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d84095ba1d4b45748a25d64cc4625eee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2ccf11253404510ac9b24d6abcdeae5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6a86656190f4410f8806e73f4ed33c41",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_2a1fdbb7a4d342689708f81a499164c6",
       "tabbable": null,
       "tooltip": null,
       "value": "üîÆ‚Äáinfer:‚Äá100%"
      }
     },
     "e41fc2b7c2814c2faa4ea53147381e9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e2ccf11253404510ac9b24d6abcdeae5",
        "IPY_MODEL_0926bbb53cad447fbc55d67c14b656c1",
        "IPY_MODEL_eb98e2a945674f8d8cc6cb7a5c5bbd0b"
       ],
       "layout": "IPY_MODEL_28b1039d37f84dba8cab09665fc67d62",
       "tabbable": null,
       "tooltip": null
      }
     },
     "eb98e2a945674f8d8cc6cb7a5c5bbd0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9f6dc804f8394a5bbfbaf695f8f1efe0",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_6668abc65a0a4f3f9349cb3a223a7a89",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1/1‚Äá[00:03&lt;00:00,‚Äá‚Äá3.39s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
